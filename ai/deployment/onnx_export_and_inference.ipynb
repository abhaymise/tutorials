{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsDGIeIaIisTb1ZUuaGMH6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhaymise/tutorials/blob/main/ai/deployment/onnx_export_and_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quyKtyEt7JZb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "# Load your PyTorch model\n",
        "model = torch.load('path/to/your/model.pth')\n",
        "model.eval()\n",
        "\n",
        "# Create a dummy input with variable batch size\n",
        "dummy_input = torch.randn(1, input_channels, input_height, input_width)  # Example: 1 sample with fixed input shape\n",
        "input_names = ['input']\n",
        "\n",
        "# Export the PyTorch model to ONNX with dynamic batch size support\n",
        "output_onnx_path = 'path/to/your/model.onnx'\n",
        "\n",
        "# Set dynamic_axes to mark the batch dimension as dynamic\n",
        "dynamic_axes = {'input': {0: 'batch_size'}}\n",
        "torch.onnx.export(model, dummy_input, output_onnx_path, input_names=input_names, dynamic_axes=dynamic_axes)\n",
        "\n",
        "# Load the exported ONNX model with ONNX Runtime\n",
        "ort_session = onnxruntime.InferenceSession(output_onnx_path)\n",
        "\n",
        "# Perform inference with a variable batch size\n",
        "batch_sizes = [1, 2, 4]  # Example: Different batch sizes\n",
        "for batch_size in batch_sizes:\n",
        "    dynamic_input = torch.randn(batch_size, input_channels, input_height, input_width)\n",
        "    dynamic_input_name = ort_session.get_inputs()[0].name\n",
        "    output = ort_session.run(None, {dynamic_input_name: dynamic_input.numpy()})\n",
        "    print(f\"Inference result for batch size {batch_size}: {output}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Resnet Model Case Study\n"
      ],
      "metadata": {
        "id": "SibkE0BZ8MrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CSQpi_rx8Hrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import onnx\n",
        "import onnxruntime\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "\n",
        "# Step 1: Load your PyTorch model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Step 2: Specify the input shape and dummy input\n",
        "input_shape = (3, 224, 224)\n",
        "dummy_input = torch.randn(1, *input_shape)\n",
        "\n",
        "# Step 3: Export the PyTorch model to ONNX with dynamic batch size support\n",
        "output_onnx_path = 'path/to/your/model.onnx'\n",
        "dynamic_axes = {'input': {0: 'batch_size'}}\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    output_onnx_path,\n",
        "    verbose=True,\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes=dynamic_axes\n",
        ")\n",
        "\n",
        "# Step 4: Load the ONNX model with ONNX Runtime\n",
        "ort_session = onnxruntime.InferenceSession(output_onnx_path)\n",
        "\n",
        "# Step 5: Preprocess the input data\n",
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_data = transform(image)\n",
        "    input_data = input_data.unsqueeze(0)  # Add batch dimension\n",
        "    return input_data.numpy()\n",
        "\n",
        "# Example usage:\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "input_data = preprocess_image(image_path)\n",
        "\n",
        "# Step 6: Run inference with ONNX Runtime\n",
        "input_name = ort_session.get_inputs()[0].name\n",
        "output_name = ort_session.get_outputs()[0].name\n",
        "result = ort_session.run([output_name], {input_name: input_data})\n",
        "\n",
        "# Step 7: Post-process the result as needed\n",
        "output_result = result[0]\n",
        "\n",
        "# Display or save the result as needed\n",
        "print(\"Model output:\", output_result)\n"
      ],
      "metadata": {
        "id": "uW15AsdH73bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLLba1o576Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization options"
      ],
      "metadata": {
        "id": "M4dJwgxk9IpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime import SessionOptions, ExecutionMode\n",
        "from onnxruntime import GraphOptimizationLevel\n",
        "\n",
        "session_options = SessionOptions()\n",
        "session_options.execution_mode = ExecutionMode.ORT_PARALLEL  # Set to parallel execution mode\n",
        "session_options.intra_op_num_threads = 4  # Number of threads per operator\n",
        "session_options.inter_op_num_threads = 2  # Number of threads across operators\n",
        "\n",
        "\n",
        "session_options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_EXTENDED\n",
        "ort_session = onnxruntime.InferenceSession(onnx_model_path, sess_options=session_options)\n",
        "# Run inference\n",
        "input_name = ort_session.get_inputs()[0].name\n",
        "output_name = ort_session.get_outputs()[0].name\n",
        "result = ort_session.run([output_name], {input_name: input_image})\n"
      ],
      "metadata": {
        "id": "8w8fu8M89LbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}